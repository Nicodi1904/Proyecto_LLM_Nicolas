import dspy

# Prueba con LM genérico de Ollama
lm = dspy.LM('ollama_chat/llama3.1', api_base='http://localhost:11434', api_key='')
dspy.configure(lm=lm)



class Explicador(dspy.Signature):
    pregunta = dspy.InputField()
    pregunta2=dspy.InputField()
    respuesta = dspy.OutputField()
    respuesta2=dspy.OutputField()
    

explicador = dspy.Predict(Explicador)
ejemplo = explicador(pregunta2="cuánto quedó Colombia Ayer", pregunta="qué te acabé de preguntar?")
print("Respuesta:", ejemplo.respuesta)
print("Respuesta:", ejemplo.respuesta2)
    
#Importantísimo notar que en DSPY, el orden en que se ingresan las preguntas importa. Primero se procesa "pregunta" luego "pregunta2"

#si le pregunto el resultado de Colombia en "pregunta" al hacerle la segunda pregunta, recordará la anterior interacción.
